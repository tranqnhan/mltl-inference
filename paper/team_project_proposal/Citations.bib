@article{Luo_Liang_Du_Wan_Peng_Zhang_2022, title={Bridging LTLf Inference to GNN Inference for Learning LTLf Formulae}, volume={36}, url={https://ojs.aaai.org/index.php/AAAI/article/view/21221}, DOI={10.1609/aaai.v36i9.21221}, abstractNote={Learning linear temporal logic on finite traces (LTLf) formulae aims to learn a target formula that characterizes the high-level behavior of a system from observation traces in planning. Existing approaches to learning LTLf formulae, however, can hardly learn accurate LTLf formulae from noisy data. It is challenging to design an efficient search mechanism in the large search space in form of arbitrary LTLf formulae while alleviating the wrong search bias resulting from noisy data. In this paper, we tackle this problem by bridging LTLf inference to GNN inference. Our key theoretical contribution is showing that GNN inference can simulate LTLf inference to distinguish traces. Based on our theoretical result, we design a GNN-based approach, GLTLf, which combines GNN inference and parameter interpretation to seek the target formula in the large search space. Thanks to the non-deterministic learning process of GNNs, GLTLf is able to cope with noise. We evaluate GLTLf on various datasets with noise. Our experimental results confirm the effectiveness of GNN inference in learning LTLf formulae and show that GLTLf is superior to the state-of-the-art approaches.}, number={9}, journal={Proceedings of the AAAI Conference on Artificial Intelligence}, author={Luo, Weilin and Liang, Pingjia and Du, Jianfeng and Wan, Hai and Peng, Bo and Zhang, Delong}, year={2022}, month={Jun.}, pages={9849-9857} }

@article{ANGLUIN_Lstar,
title = {Learning regular sets from queries and counterexamples},
journal = {Information and Computation},
volume = {75},
number = {2},
pages = {87-106},
year = {1987},
issn = {0890-5401},
doi = {https://doi.org/10.1016/0890-5401(87)90052-6},
url = {https://www.sciencedirect.com/science/article/pii/0890540187900526},
author = {Dana Angluin},
abstract = {The problem of identifying an unknown regular set from examples of its members and nonmembers is addressed. It is assumed that the regular set is presented by a minimally adequate Teacher, which can answer membership queries about the set and can also test a conjecture and indicate whether it is equal to the unknown set and provide a counterexample if not. (A counterexample is a string in the symmetric difference of the correct set and the conjectured set.) A learning algorithm L∗ is described that correctly learns any regular set from any minimally adequate Teacher in time polynomial in the number of states of the minimum dfa for the set and the maximum length of any counterexample provided by the Teacher. It is shown that in a stochastic setting the ability of the Teacher to test conjectures may be replaced by a random sampling oracle, EX( ). A polynomial-time learning algorithm is shown for a particular problem of context-free language identification.}
}

@inproceedings{roy_ltlf_learning,
author = {Roy, Rajarshi and Gaglione, Jean-Rapha\"{e}l and Baharisangari, Nasim and Neider, Daniel and Xu, Zhe and Topcu, Ufuk},
title = {Learning Interpretable Temporal Properties from Positive Examples Only},
year = {2023},
isbn = {978-1-57735-880-0},
publisher = {AAAI Press},
url = {https://doi.org/10.1609/aaai.v37i5.25800},
doi = {10.1609/aaai.v37i5.25800},
abstract = {We consider the problem of explaining the temporal behavior of black-box systems using human-interpretable models. Following recent research trends, we rely on the fundamental yet interpretable models of deterministic finite automata (DFAs) and linear temporal logic (LTLf) formulas. In contrast to most existing works for learning DFAs and LTLf formulas, we consider learning from only positive examples. Our motivation is that negative examples are generally difficult to observe, in particular, from black-box systems. To learn meaningful models from positive examples only, we design algorithms that rely on conciseness and language minimality of models as regularizers. Our learning algorithms are based on two approaches: a symbolic and a counterexample-guided one. The symbolic approach exploits an efficient encoding of language minimality as a constraint satisfaction problem, whereas the counterexample-guided one relies on generating suitable negative examples to guide the learning. Both approaches provide us with effective algorithms with minimality guarantees on the learned models. To assess the effectiveness of our algorithms, we evaluate them on a few practical case studies.},
booktitle = {Proceedings of the Thirty-Seventh AAAI Conference on Artificial Intelligence and Thirty-Fifth Conference on Innovative Applications of Artificial Intelligence and Thirteenth Symposium on Educational Advances in Artificial Intelligence},
articleno = {731},
numpages = {9},
series = {AAAI'23/IAAI'23/EAAI'23}
}

@article{camacho_ltlf_learning, title={Learning Interpretable Models Expressed in Linear Temporal Logic}, volume={29}, url={https://ojs.aaai.org/index.php/ICAPS/article/view/3529}, DOI={10.1609/icaps.v29i1.3529}, abstractNote={&lt;p&gt;We examine the problem of learning models that characterize the high-level behavior of a system based on observation traces. Our aim is to develop models that are human interpretable. To this end, we introduce the problem of learning a &lt;em&gt;Linear Temporal Logic&lt;/em&gt; (LTL) formula that parsimoniously captures a given set of positive and negative example traces. Our approach to learning LTL exploits a symbolic state representation, searching through a space of labeled skeleton formulae to construct an alternating automaton that models observed behavior, from which the LTL can be read off. Construction of interpretable behavior models is central to a diversity of applications related to planning and plan recognition. We showcase the relevance and significance of our work in the context of behavior description and discrimination: i) active learning of a human-interpretable behavior model that describes observed examples obtained by interaction with an oracle; ii) passive learning of a classifier that discriminates individual agents, based on the human-interpretable signature way in which they perform particular tasks. Experiments demonstrate the effectiveness of our symbolic model learning approach in providing human-interpretable models and classifiers from reduced example sets.&lt;/p&gt;}, number={1}, journal={Proceedings of the International Conference on Automated Planning and Scheduling}, author={Camacho, Alberto and McIlraith, Sheila A.}, year={2021}, month={May}, pages={621-630} }

@INPROCEEDINGS{stl_learning,
  author={Li, Danyang and Cai, Mingyu and Vasile, Cristian-Ioan and Tron, Roberto},
  booktitle={2023 American Control Conference (ACC)}, 
  title={Learning Signal Temporal Logic through Neural Network for Interpretable Classification}, 
  year={2023},
  volume={},
  number={},
  pages={1907-1914},
  doi={10.23919/ACC55779.2023.10156357}}

@inproceedings{ponyge2,
author = {Fenton, Michael and McDermott, James and Fagan, David and Forstenlechner, Stefan and Hemberg, Erik and O'Neill, Michael},
title = {PonyGE2: Grammatical Evolution in Python},
year = {2017},
isbn = {9781450349390},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3067695.3082469},
doi = {10.1145/3067695.3082469},
abstract = {Grammatical Evolution (GE) is a population-based evolutionary algorithm, where a formal grammar is used in the genotype to phenotype mapping process. PonyGE2 is an open source implementation of GE in Python, developed at UCD's Natural Computing Research and Applications group. It is intended as an advertisement and a starting-point for those new to GE, a reference for students and researchers, a rapid-prototyping medium for our own experiments, and a Python workout. As well as providing the characteristic genotype to phenotype mapping of GE, a search algorithm engine is also provided. A number of sample problems and tutorials on how to use and adapt PonyGE2 have been developed.},
booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference Companion},
pages = {1194–1201},
numpages = {8},
keywords = {grammatical evolution, genetic programming},
location = {Berlin, Germany},
series = {GECCO '17}
}

@inproceedings{dwyer,
author = {Dwyer, Matthew B. and Avrunin, George S. and Corbett, James C.},
title = {Patterns in Property Specifications for Finite-State Verification},
year = {1999},
isbn = {1581130740},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/302405.302672},
doi = {10.1145/302405.302672},
booktitle = {Proceedings of the 21st International Conference on Software Engineering},
pages = {411–420},
numpages = {10},
keywords = {finite-state verification, patterns, formal specification, concurrent systems},
location = {Los Angeles, California, USA},
series = {ICSE '99}
}